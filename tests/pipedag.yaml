name: pipedag_tests
table_store_connections:
  postgres:
    # Postgres: this can be used after running `docker-compose up`
    url: "postgresql://{$POSTGRES_USERNAME}:{$POSTGRES_PASSWORD}@127.0.0.1:6543/{instance_id}"

  mssql:
    # SQL Server: this can be used after running `docker-compose up`
    url: "mssql+pyodbc://{$MSSQL_USERNAME}:{$MSSQL_PASSWORD}@127.0.0.1:1433/master?driver=ODBC+Driver+18+for+SQL+Server&encrypt=no"
    schema_prefix: "{instance_id}_"  # SQL Server needs database.schema
    schema_suffix: ".dbo"   # Alternatively SQL Server databases can be used as schemas with .dbo default schema

  ibm_db2:
    # SQL Server: this can be used after running `docker-compose up`
    url: "db2+ibm_db://db2inst1:password@localhost:50000/testdb"
    schema_prefix: "{instance_id}_"

instances:
  __any__:
    # listen-interface for pipedag context server which synchronizes some task state during DAG execution
    network_interface: "127.0.0.1"
    # classes to be materialized to table store even without pipedag Table wrapper (we have loose coupling between
    # pipedag and pydiverse.transform, so consider adding 'pydiverse.transform.Table' in your config)
    auto_table: ["pandas.DataFrame", "sqlalchemy.Table"]
    # abort as fast a possible on task failure and print most readable stack trace
    fail_fast: true

    instance_id: pipedag_default
    table_store:
      class: "pydiverse.pipedag.backend.table.SQLTableStore"

      # Postgres: this can be used after running `docker-compose up`
      table_store_connection: postgres
      create_database_if_not_exists: True

      ## SQL Server: this can be used after running `docker-compose up`
      #table_store_connection: mssql

      # print select statements before being encapsualted in materialize expressions and tables before writing to
      # database
      print_materialize: true
      # print final sql statements
      print_sql: true

    blob_store:
      class: "pydiverse.pipedag.backend.blob.FileBlobStore"
      base_path: "/tmp/pipedag/blobs"

    lock_manager:
      class: "pydiverse.pipedag.backend.lock.ZooKeeperLockManager"
      hosts: "localhost:2181"

    orchestration:
      class: "pydiverse.pipedag.engine.SequentialEngine"
      ## Activate this class to work either with prefect 1.3.0 or prefect 2.0
      # class: "pydiverse.pipedag.engine.PrefectEngine"
  mssql:
    # Full dataset is using default database connection and schemas
    table_store:
      table_store_connection: mssql
  ibm_db2:
    # Full dataset is using default database connection and schemas
    table_store:
      table_store_connection: ibm_db2
